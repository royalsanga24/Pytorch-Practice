{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad992ee5-9bb2-43d8-9b25-2688878e43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557ad851-563e-47b8-9b61-06193c202a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79a29d4-309c-4f87-aae5-5b07e4e8c1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd864135-73e1-433c-92c8-e8200d91b8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a6a4f1-026b-4f10-91f2-d3f9b04e55aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0],\n",
       "         [ 0,  0,  5],\n",
       "         [ 0,  5, 13],\n",
       "         [ 5, 13, 13],\n",
       "         [13, 13,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 15],\n",
       "         [ 0, 15, 12],\n",
       "         [15, 12,  9],\n",
       "         [12,  9, 22],\n",
       "         [ 9, 22,  9],\n",
       "         [22,  9,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  1],\n",
       "         [ 0,  1, 22],\n",
       "         [ 1, 22,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  9],\n",
       "         [ 0,  9, 19],\n",
       "         [ 9, 19,  1],\n",
       "         [19,  1,  2],\n",
       "         [ 1,  2,  5],\n",
       "         [ 2,  5, 12],\n",
       "         [ 5, 12, 12],\n",
       "         [12, 12,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 19],\n",
       "         [ 0, 19, 15],\n",
       "         [19, 15, 16],\n",
       "         [15, 16,  8],\n",
       "         [16,  8,  9],\n",
       "         [ 8,  9,  1]]),\n",
       " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "          1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 3\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "    context = [0]*block_size\n",
    "    for ch in w+'.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix]\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b0ea4f-21d0-435f-afc8-350dd24d5c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]), torch.int64, torch.int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, X.dtype, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1df8557-b609-4fb5-8f19-dacb72e79ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063701d5-b823-4085-b6f8-de9185878e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7420,  1.4020],\n",
       "        [-0.2300, -0.4950],\n",
       "        [ 0.4954,  0.3850],\n",
       "        [ 0.4717, -1.3112],\n",
       "        [ 0.5573, -0.7186],\n",
       "        [-0.7635,  0.4223],\n",
       "        [-1.8353, -1.2933],\n",
       "        [ 1.2059, -1.4008],\n",
       "        [-0.5531, -0.7053],\n",
       "        [-0.7553, -1.3448],\n",
       "        [ 1.2876,  1.0932],\n",
       "        [ 0.7668, -0.2078],\n",
       "        [ 0.1897,  1.6719],\n",
       "        [ 0.9076, -0.6886],\n",
       "        [ 1.4464, -0.2366],\n",
       "        [ 0.4161, -0.2882],\n",
       "        [ 0.3232,  1.0323],\n",
       "        [-0.3653,  0.2720],\n",
       "        [ 1.5304, -0.8151],\n",
       "        [ 0.0960,  0.3321],\n",
       "        [ 1.4336,  0.1962],\n",
       "        [-2.2178,  0.5528],\n",
       "        [-0.8506,  1.1200],\n",
       "        [-1.1165, -0.5208],\n",
       "        [-0.4158,  0.0659],\n",
       "        [-1.8557,  1.2911],\n",
       "        [-0.8943, -0.8668]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "671de702-25e9-4bf9-9ac4-d11ee4889b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 2]),\n",
       " tensor([[[-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020],\n",
       "          [-0.7635,  0.4223]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-0.7635,  0.4223],\n",
       "          [ 0.9076, -0.6886]],\n",
       " \n",
       "         [[-0.7635,  0.4223],\n",
       "          [ 0.9076, -0.6886],\n",
       "          [ 0.9076, -0.6886]],\n",
       " \n",
       "         [[ 0.9076, -0.6886],\n",
       "          [ 0.9076, -0.6886],\n",
       "          [-0.2300, -0.4950]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020],\n",
       "          [ 0.4161, -0.2882]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [ 0.4161, -0.2882],\n",
       "          [ 0.1897,  1.6719]],\n",
       " \n",
       "         [[ 0.4161, -0.2882],\n",
       "          [ 0.1897,  1.6719],\n",
       "          [-0.7553, -1.3448]],\n",
       " \n",
       "         [[ 0.1897,  1.6719],\n",
       "          [-0.7553, -1.3448],\n",
       "          [-0.8506,  1.1200]],\n",
       " \n",
       "         [[-0.7553, -1.3448],\n",
       "          [-0.8506,  1.1200],\n",
       "          [-0.7553, -1.3448]],\n",
       " \n",
       "         [[-0.8506,  1.1200],\n",
       "          [-0.7553, -1.3448],\n",
       "          [-0.2300, -0.4950]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020],\n",
       "          [-0.2300, -0.4950]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-0.2300, -0.4950],\n",
       "          [-0.8506,  1.1200]],\n",
       " \n",
       "         [[-0.2300, -0.4950],\n",
       "          [-0.8506,  1.1200],\n",
       "          [-0.2300, -0.4950]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020],\n",
       "          [-0.7553, -1.3448]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-0.7553, -1.3448],\n",
       "          [ 0.0960,  0.3321]],\n",
       " \n",
       "         [[-0.7553, -1.3448],\n",
       "          [ 0.0960,  0.3321],\n",
       "          [-0.2300, -0.4950]],\n",
       " \n",
       "         [[ 0.0960,  0.3321],\n",
       "          [-0.2300, -0.4950],\n",
       "          [ 0.4954,  0.3850]],\n",
       " \n",
       "         [[-0.2300, -0.4950],\n",
       "          [ 0.4954,  0.3850],\n",
       "          [-0.7635,  0.4223]],\n",
       " \n",
       "         [[ 0.4954,  0.3850],\n",
       "          [-0.7635,  0.4223],\n",
       "          [ 0.1897,  1.6719]],\n",
       " \n",
       "         [[-0.7635,  0.4223],\n",
       "          [ 0.1897,  1.6719],\n",
       "          [ 0.1897,  1.6719]],\n",
       " \n",
       "         [[ 0.1897,  1.6719],\n",
       "          [ 0.1897,  1.6719],\n",
       "          [-0.2300, -0.4950]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [-1.7420,  1.4020],\n",
       "          [ 0.0960,  0.3321]],\n",
       " \n",
       "         [[-1.7420,  1.4020],\n",
       "          [ 0.0960,  0.3321],\n",
       "          [ 0.4161, -0.2882]],\n",
       " \n",
       "         [[ 0.0960,  0.3321],\n",
       "          [ 0.4161, -0.2882],\n",
       "          [ 0.3232,  1.0323]],\n",
       " \n",
       "         [[ 0.4161, -0.2882],\n",
       "          [ 0.3232,  1.0323],\n",
       "          [-0.5531, -0.7053]],\n",
       " \n",
       "         [[ 0.3232,  1.0323],\n",
       "          [-0.5531, -0.7053],\n",
       "          [-0.7553, -1.3448]],\n",
       " \n",
       "         [[-0.5531, -0.7053],\n",
       "          [-0.7553, -1.3448],\n",
       "          [-0.2300, -0.4950]]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embedding matrix\n",
    "emb = C[X]\n",
    "emb.shape, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbf671f-e065-4b3b-b5a0-8d609d6b601c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 1]),\n",
       " tensor([[-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.2300, -0.4950]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[13], C[X][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec3a2b27-1646-47b7-8c28-8ed2029f358b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5394, -0.6147,  0.0316, -0.2055,  0.1993, -0.0935, -0.9306, -0.7493,\n",
       "          -2.2087,  1.0324,  1.2198, -1.1996,  0.7869, -0.1540, -1.6660,  0.3867,\n",
       "          -0.4527, -0.7049, -1.6179, -1.7732,  1.0061,  0.5348, -0.3137,  0.4364,\n",
       "          -0.4962,  1.6743, -0.2202, -1.1451, -0.3874, -0.4601,  0.0736, -0.3902,\n",
       "           0.4710, -0.7395, -0.3943,  0.2420, -0.5568, -0.4236,  0.1582,  0.2149,\n",
       "           0.2591,  1.1098,  1.9753,  1.0986,  0.0065, -0.0239, -0.6852, -0.1071,\n",
       "          -1.3501,  1.1936,  0.3413, -0.8965, -1.5036,  0.1129,  1.3717, -1.6917,\n",
       "          -1.3425, -0.2785,  0.4911,  0.2785,  0.1357, -0.6746, -1.7251,  0.3667,\n",
       "           3.2040, -1.4828, -0.0453,  1.5101, -0.1833, -1.1133,  0.8091,  0.1163,\n",
       "           1.1542, -0.9709,  1.3458,  0.6276,  0.9580,  0.0066,  0.9063, -0.0762,\n",
       "          -1.0078, -0.4574, -0.6292, -0.1965, -2.0233,  0.0264,  0.9327, -0.8434,\n",
       "          -0.8583,  0.4383, -0.4126, -1.3698, -1.0923, -0.3226,  0.0200, -0.3484,\n",
       "           0.9537,  1.2382,  0.6543,  0.7927],\n",
       "         [ 0.0463,  1.0288, -0.8715, -0.2490,  0.3508,  0.1074,  0.5975,  0.5052,\n",
       "          -0.5315,  1.8837,  0.4183, -0.5145, -0.6144, -0.8786,  0.5200, -2.0845,\n",
       "          -0.3606, -1.0674,  0.0442, -2.0854,  0.2581, -1.0986, -0.1114, -1.5165,\n",
       "          -0.9412,  0.4879, -0.3543, -1.1330,  0.7319, -0.1054, -1.3816,  0.8195,\n",
       "          -0.7696, -1.1640,  0.3497, -0.4979, -0.0430, -0.2323, -0.2653,  1.1644,\n",
       "          -1.7862,  0.8462, -0.8850,  0.3821,  0.2593, -0.5665, -1.4812, -0.3768,\n",
       "          -1.0609,  1.1198,  0.4657, -0.7564, -0.5276, -0.4695, -0.7118, -0.2473,\n",
       "           0.3554, -0.5901,  0.8652,  1.3084,  0.0994, -1.1862,  0.1468,  0.5805,\n",
       "          -0.7878, -0.4332,  0.1309,  2.1648, -0.1375, -0.3936,  0.0336, -1.0856,\n",
       "          -1.4375, -0.9018,  0.1732, -1.0753,  2.1660,  0.3081,  1.0670,  0.0942,\n",
       "           0.2920, -0.1930,  1.4732, -0.1777,  0.4366,  0.4412, -1.3442, -0.5111,\n",
       "          -1.3733, -0.8566, -0.1096, -0.6253,  0.0825, -0.2675, -1.4895,  0.1703,\n",
       "           2.7046, -0.4121,  0.2691, -0.8216],\n",
       "         [ 0.7212, -0.2020, -0.0725,  0.6035,  0.9066,  0.3149,  0.4162,  0.3572,\n",
       "          -0.9370, -0.7365,  1.1384,  1.3903,  0.3624, -0.6520,  0.1459, -0.6520,\n",
       "          -0.1683, -0.4886,  0.1189, -0.2436,  1.1787,  0.2008,  1.2973,  1.3428,\n",
       "          -0.8269,  0.7925, -2.2065, -0.6198, -0.1550,  1.8073,  0.6139, -0.0389,\n",
       "          -0.4299, -0.6742, -1.0156,  2.0331,  0.7225, -1.1788,  1.2672, -0.5870,\n",
       "          -0.2606, -0.6065, -1.4335, -0.6933,  0.9936, -0.4124,  0.8317,  0.3653,\n",
       "           0.9841,  0.2784, -1.8913,  1.0258,  1.1812,  1.2365, -0.8059,  1.0936,\n",
       "          -1.2711, -0.6292,  0.4616,  1.4491, -1.6027, -0.5936,  1.8275, -0.7244,\n",
       "           1.0753, -0.3162, -0.8220,  1.0157,  0.4629, -0.6735, -0.4533,  0.3907,\n",
       "           0.0967, -0.1838, -0.6758, -2.5032,  1.8857,  0.7105,  2.3029,  0.1903,\n",
       "          -0.1691, -1.3182,  0.2798,  1.6195, -0.9964, -1.1053, -0.6985,  0.1870,\n",
       "          -1.2905,  0.2406, -0.8022, -0.5688,  1.0059, -0.8001,  1.2653, -0.8610,\n",
       "           0.1228,  0.4465,  0.2553, -1.4750],\n",
       "         [-0.7386,  0.2043,  0.2892,  0.3716,  0.1863,  0.2202,  0.6150, -0.5357,\n",
       "          -0.5473,  0.4279,  0.8187, -1.5404, -0.5930, -0.7076,  0.8484,  1.9387,\n",
       "           0.9206, -0.2583, -1.1625, -0.3917, -0.2939,  0.8519,  1.0318, -0.5666,\n",
       "           0.4290,  0.6677,  0.2007,  1.6119, -0.0614, -1.3046,  0.3876, -0.6437,\n",
       "           0.2741,  1.0895,  1.1950, -1.4504, -1.2043, -2.5867,  0.6154, -0.3831,\n",
       "           0.8047, -0.6246, -0.1759,  0.7557, -2.6281,  0.3637, -0.3669, -0.9351,\n",
       "          -1.3879, -0.2998, -0.6697,  0.8975, -0.5872,  0.6346,  1.4816, -0.2676,\n",
       "           1.7413,  0.3525,  0.7324, -1.2515,  0.7939, -0.8393, -0.6582, -1.1084,\n",
       "           0.4681, -0.7557, -1.7361,  1.1714,  0.5722,  0.7520, -0.3343,  1.5102,\n",
       "          -1.1407, -0.1951,  0.6669,  0.2078, -1.4684,  1.3350, -0.6282, -0.5384,\n",
       "           1.7441,  0.0510,  0.5854, -0.3963,  0.4149, -1.8159, -0.5068, -0.0610,\n",
       "           0.5208,  0.5852, -0.3048,  0.4578,  1.2073,  0.0942, -0.5223, -0.4948,\n",
       "           0.1558, -0.5548, -1.0488,  1.4061],\n",
       "         [ 0.3908, -0.0299, -2.5732, -0.5607,  0.8562,  0.9225, -0.5461, -1.6025,\n",
       "           0.5423, -0.2941, -0.8496,  0.8486,  0.6503, -0.9593, -0.5854,  0.2449,\n",
       "           1.1635, -0.6122,  1.5303,  1.2140, -0.4391,  0.2362, -0.1547, -0.4209,\n",
       "          -0.7644, -0.2885,  0.1227,  1.6762,  0.4650, -0.3774, -0.8042, -0.8628,\n",
       "           0.8267, -1.8860,  0.7783, -1.1348, -1.4765, -0.1139,  0.4671, -1.6370,\n",
       "           0.2898,  1.5782, -0.2462,  0.0399,  0.3518, -1.1112,  1.0772,  2.6629,\n",
       "          -0.2475, -0.5984,  1.0572,  0.3356,  1.3383, -0.3192,  0.5063, -1.5121,\n",
       "           0.7882, -1.2720, -0.4661, -1.5193, -0.8341,  1.8729,  2.8890, -0.2536,\n",
       "           0.7808, -1.2046, -0.4454, -0.7360,  0.8067,  0.1304,  0.2842, -0.9603,\n",
       "          -0.1366,  0.5418,  0.7088,  1.2691, -0.5274, -1.1034,  0.5817,  0.0116,\n",
       "           0.4706,  0.5868, -1.2578, -0.2064,  0.5053,  0.3881,  1.8123,  0.5199,\n",
       "          -1.0021, -0.0433, -0.4897,  0.6084, -0.7730, -0.5133, -1.1801, -2.5518,\n",
       "          -0.9123,  1.0097,  0.4795, -0.2603],\n",
       "         [ 1.5280, -1.0783, -0.1224, -0.6191, -0.6088, -0.1518,  0.0690, -1.1364,\n",
       "           1.4763, -0.6415, -0.1609,  0.3164, -0.3634,  0.8613, -1.5494,  0.4455,\n",
       "          -0.5550,  1.7664, -1.5423,  0.6019, -0.7105, -1.1461,  1.3901,  1.4864,\n",
       "          -0.3451, -0.6498, -1.6486, -0.8942,  0.4353,  0.6634,  0.5360,  0.8903,\n",
       "           0.6595, -0.2295,  0.9029, -1.2636, -0.4291,  0.7558, -0.5951, -1.6529,\n",
       "          -1.1224, -1.4686,  0.8050, -0.9906,  0.2359,  1.5762, -1.0195, -0.7549,\n",
       "           1.3089, -1.3836, -0.2951, -0.6939, -0.3419, -1.3064, -0.8613,  0.9917,\n",
       "          -0.5725, -0.2348, -1.7739, -0.6307,  0.5951,  0.2160, -0.5134,  0.3697,\n",
       "           0.8651, -0.4673,  0.2708, -0.0175,  0.5321, -0.5798,  0.9949, -0.1909,\n",
       "          -0.5415,  0.0393,  0.9250, -1.6275,  1.6923, -2.1830,  1.1705, -0.0637,\n",
       "           0.5462, -0.2366,  1.7178, -0.7996,  0.8117, -0.6279, -1.7666,  0.1958,\n",
       "           0.9713,  0.9229,  1.9567, -0.6197, -1.0584, -0.8073,  0.9221, -0.7889,\n",
       "           0.5316,  0.0985,  1.1364, -0.6205]]),\n",
       " tensor([-1.6235, -0.2068, -0.3995,  1.8263, -0.4260, -0.7322, -0.6475,  0.4534,\n",
       "          0.6248,  0.2925,  0.0139,  1.0750,  1.1888, -0.5649, -0.2350,  2.3402,\n",
       "         -1.3291, -1.3291,  0.0723,  0.8697, -0.1110, -0.4659, -2.2273, -0.3013,\n",
       "         -0.1570,  0.0501,  0.6199, -0.3966, -0.4045, -0.1988,  1.5548,  1.5016,\n",
       "         -0.9814, -0.8232, -0.8776, -0.3372,  0.2179, -0.3955,  0.7999, -0.7919,\n",
       "         -0.2078, -0.7624,  0.0807, -0.4540, -0.6957,  1.9864, -0.5092,  0.3224,\n",
       "         -0.3564, -0.1403,  0.5779,  0.5060, -1.1805,  0.8095, -1.1921,  1.1972,\n",
       "          0.8490,  0.5101,  1.4974, -0.1018, -1.5890, -1.0702, -0.8187, -1.8216,\n",
       "          0.6639,  3.1178, -1.4362, -2.5303, -1.3278, -0.1768, -1.0039, -1.2171,\n",
       "          0.4865,  0.1062,  0.7926,  0.0870, -0.9270, -1.1726, -0.1971,  1.3081,\n",
       "         -0.1594,  1.6494, -1.8454,  0.4347, -1.0512,  1.2969, -0.6185,  0.9589,\n",
       "         -0.1545,  0.4265, -0.8164, -0.8026, -1.0516, -0.0684, -0.7671, -0.4069,\n",
       "         -0.1120, -2.0112,  1.6283, -0.0657]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomly initialized weights and biases\n",
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)\n",
    "W1, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad21816c-2252-4375-98cf-a57d7d0239c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 100]), torch.Size([100]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape, b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82f6f2de-cb9b-47af-b747-ee0d4850176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.9076, -0.6886],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-0.8506,  1.1200],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.7553, -1.3448],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [-0.2300, -0.4950],\n",
       "         [ 0.4954,  0.3850],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.3232,  1.0323],\n",
       "         [-0.5531, -0.7053]]),\n",
       " tensor([[-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.9076, -0.6886],\n",
       "         [ 0.9076, -0.6886],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-0.8506,  1.1200],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-0.8506,  1.1200],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.7553, -1.3448],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [-0.2300, -0.4950],\n",
       "         [ 0.4954,  0.3850],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.3232,  1.0323],\n",
       "         [-0.5531, -0.7053],\n",
       "         [-0.7553, -1.3448]]),\n",
       " tensor([[-1.7420,  1.4020],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.9076, -0.6886],\n",
       "         [ 0.9076, -0.6886],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-0.8506,  1.1200],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-0.8506,  1.1200],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.7553, -1.3448],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [-0.2300, -0.4950],\n",
       "         [ 0.4954,  0.3850],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.3232,  1.0323],\n",
       "         [-0.5531, -0.7053],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-0.2300, -0.4950]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 Input nueron example\n",
    "emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3216706-8317-495a-bb39-30cdaa035122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -0.7635,  0.4223],\n",
       "        [-1.7420,  1.4020, -0.7635,  0.4223,  0.9076, -0.6886],\n",
       "        [-0.7635,  0.4223,  0.9076, -0.6886,  0.9076, -0.6886],\n",
       "        [ 0.9076, -0.6886,  0.9076, -0.6886, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020,  0.4161, -0.2882],\n",
       "        [-1.7420,  1.4020,  0.4161, -0.2882,  0.1897,  1.6719],\n",
       "        [ 0.4161, -0.2882,  0.1897,  1.6719, -0.7553, -1.3448],\n",
       "        [ 0.1897,  1.6719, -0.7553, -1.3448, -0.8506,  1.1200],\n",
       "        [-0.7553, -1.3448, -0.8506,  1.1200, -0.7553, -1.3448],\n",
       "        [-0.8506,  1.1200, -0.7553, -1.3448, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -0.2300, -0.4950, -0.8506,  1.1200],\n",
       "        [-0.2300, -0.4950, -0.8506,  1.1200, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -0.7553, -1.3448],\n",
       "        [-1.7420,  1.4020, -0.7553, -1.3448,  0.0960,  0.3321],\n",
       "        [-0.7553, -1.3448,  0.0960,  0.3321, -0.2300, -0.4950],\n",
       "        [ 0.0960,  0.3321, -0.2300, -0.4950,  0.4954,  0.3850],\n",
       "        [-0.2300, -0.4950,  0.4954,  0.3850, -0.7635,  0.4223],\n",
       "        [ 0.4954,  0.3850, -0.7635,  0.4223,  0.1897,  1.6719],\n",
       "        [-0.7635,  0.4223,  0.1897,  1.6719,  0.1897,  1.6719],\n",
       "        [ 0.1897,  1.6719,  0.1897,  1.6719, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020,  0.0960,  0.3321],\n",
       "        [-1.7420,  1.4020,  0.0960,  0.3321,  0.4161, -0.2882],\n",
       "        [ 0.0960,  0.3321,  0.4161, -0.2882,  0.3232,  1.0323],\n",
       "        [ 0.4161, -0.2882,  0.3232,  1.0323, -0.5531, -0.7053],\n",
       "        [ 0.3232,  1.0323, -0.5531, -0.7053, -0.7553, -1.3448],\n",
       "        [-0.5531, -0.7053, -0.7553, -1.3448, -0.2300, -0.4950]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatinating the second dimension of each to match Weight Matrix W1's dimensions\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46d50687-a7c0-49e6-8737-201014c2c840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.9076, -0.6886],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-0.8506,  1.1200],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.7553, -1.3448],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [-0.2300, -0.4950],\n",
       "         [ 0.4954,  0.3850],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.3232,  1.0323],\n",
       "         [-0.5531, -0.7053]]),\n",
       " tensor([[-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.9076, -0.6886],\n",
       "         [ 0.9076, -0.6886],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-0.8506,  1.1200],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-0.8506,  1.1200],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.7553, -1.3448],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [-0.2300, -0.4950],\n",
       "         [ 0.4954,  0.3850],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.3232,  1.0323],\n",
       "         [-0.5531, -0.7053],\n",
       "         [-0.7553, -1.3448]]),\n",
       " tensor([[-1.7420,  1.4020],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.9076, -0.6886],\n",
       "         [ 0.9076, -0.6886],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-0.8506,  1.1200],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-0.8506,  1.1200],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-1.7420,  1.4020],\n",
       "         [-0.7553, -1.3448],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [-0.2300, -0.4950],\n",
       "         [ 0.4954,  0.3850],\n",
       "         [-0.7635,  0.4223],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [ 0.1897,  1.6719],\n",
       "         [-0.2300, -0.4950],\n",
       "         [-1.7420,  1.4020],\n",
       "         [ 0.0960,  0.3321],\n",
       "         [ 0.4161, -0.2882],\n",
       "         [ 0.3232,  1.0323],\n",
       "         [-0.5531, -0.7053],\n",
       "         [-0.7553, -1.3448],\n",
       "         [-0.2300, -0.4950]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of torch.unbind\n",
    "torch.unbind(emb, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8451edb3-e78f-4e63-9186-74a7c0a7c79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -0.7635,  0.4223],\n",
       "        [-1.7420,  1.4020, -0.7635,  0.4223,  0.9076, -0.6886],\n",
       "        [-0.7635,  0.4223,  0.9076, -0.6886,  0.9076, -0.6886],\n",
       "        [ 0.9076, -0.6886,  0.9076, -0.6886, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020,  0.4161, -0.2882],\n",
       "        [-1.7420,  1.4020,  0.4161, -0.2882,  0.1897,  1.6719],\n",
       "        [ 0.4161, -0.2882,  0.1897,  1.6719, -0.7553, -1.3448],\n",
       "        [ 0.1897,  1.6719, -0.7553, -1.3448, -0.8506,  1.1200],\n",
       "        [-0.7553, -1.3448, -0.8506,  1.1200, -0.7553, -1.3448],\n",
       "        [-0.8506,  1.1200, -0.7553, -1.3448, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -0.2300, -0.4950, -0.8506,  1.1200],\n",
       "        [-0.2300, -0.4950, -0.8506,  1.1200, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -0.7553, -1.3448],\n",
       "        [-1.7420,  1.4020, -0.7553, -1.3448,  0.0960,  0.3321],\n",
       "        [-0.7553, -1.3448,  0.0960,  0.3321, -0.2300, -0.4950],\n",
       "        [ 0.0960,  0.3321, -0.2300, -0.4950,  0.4954,  0.3850],\n",
       "        [-0.2300, -0.4950,  0.4954,  0.3850, -0.7635,  0.4223],\n",
       "        [ 0.4954,  0.3850, -0.7635,  0.4223,  0.1897,  1.6719],\n",
       "        [-0.7635,  0.4223,  0.1897,  1.6719,  0.1897,  1.6719],\n",
       "        [ 0.1897,  1.6719,  0.1897,  1.6719, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020,  0.0960,  0.3321],\n",
       "        [-1.7420,  1.4020,  0.0960,  0.3321,  0.4161, -0.2882],\n",
       "        [ 0.0960,  0.3321,  0.4161, -0.2882,  0.3232,  1.0323],\n",
       "        [ 0.4161, -0.2882,  0.3232,  1.0323, -0.5531, -0.7053],\n",
       "        [ 0.3232,  1.0323, -0.5531, -0.7053, -0.7553, -1.3448],\n",
       "        [-0.5531, -0.7053, -0.7553, -1.3448, -0.2300, -0.4950]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cat and unvind together to avoid hardcoding dimensions and match emb and W1's dimensions\n",
    "torch.cat(torch.unbind(emb , 1), 1)\n",
    "# Output is same as torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1) but neurons and dimensions are not hard-coded, therefore is better for variable block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf798a3-0ebc-4992-9c34-e171453ebed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -0.7635,  0.4223],\n",
       "        [-1.7420,  1.4020, -0.7635,  0.4223,  0.9076, -0.6886],\n",
       "        [-0.7635,  0.4223,  0.9076, -0.6886,  0.9076, -0.6886],\n",
       "        [ 0.9076, -0.6886,  0.9076, -0.6886, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020,  0.4161, -0.2882],\n",
       "        [-1.7420,  1.4020,  0.4161, -0.2882,  0.1897,  1.6719],\n",
       "        [ 0.4161, -0.2882,  0.1897,  1.6719, -0.7553, -1.3448],\n",
       "        [ 0.1897,  1.6719, -0.7553, -1.3448, -0.8506,  1.1200],\n",
       "        [-0.7553, -1.3448, -0.8506,  1.1200, -0.7553, -1.3448],\n",
       "        [-0.8506,  1.1200, -0.7553, -1.3448, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -0.2300, -0.4950, -0.8506,  1.1200],\n",
       "        [-0.2300, -0.4950, -0.8506,  1.1200, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -0.7553, -1.3448],\n",
       "        [-1.7420,  1.4020, -0.7553, -1.3448,  0.0960,  0.3321],\n",
       "        [-0.7553, -1.3448,  0.0960,  0.3321, -0.2300, -0.4950],\n",
       "        [ 0.0960,  0.3321, -0.2300, -0.4950,  0.4954,  0.3850],\n",
       "        [-0.2300, -0.4950,  0.4954,  0.3850, -0.7635,  0.4223],\n",
       "        [ 0.4954,  0.3850, -0.7635,  0.4223,  0.1897,  1.6719],\n",
       "        [-0.7635,  0.4223,  0.1897,  1.6719,  0.1897,  1.6719],\n",
       "        [ 0.1897,  1.6719,  0.1897,  1.6719, -0.2300, -0.4950],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020, -1.7420,  1.4020],\n",
       "        [-1.7420,  1.4020, -1.7420,  1.4020,  0.0960,  0.3321],\n",
       "        [-1.7420,  1.4020,  0.0960,  0.3321,  0.4161, -0.2882],\n",
       "        [ 0.0960,  0.3321,  0.4161, -0.2882,  0.3232,  1.0323],\n",
       "        [ 0.4161, -0.2882,  0.3232,  1.0323, -0.5531, -0.7053],\n",
       "        [ 0.3232,  1.0323, -0.5531, -0.7053, -0.7553, -1.3448],\n",
       "        [-0.5531, -0.7053, -0.7553, -1.3448, -0.2300, -0.4950]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Efficient way is to use torch.view instead of cat and/or unbind\n",
    "emb.view(emb.shape[0], 6)\n",
    "# Output is same as torch.cat(torch.unbind(emb , 1), 1) but is much more efficient than cat as .view() manipulates 'storage' component of neurons instead of creating new neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "094ab7f8-0910-43e5-b0df-b7b138049b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8956,  0.9024,  0.9965,  ..., -1.0000, -0.2833,  0.9097],\n",
       "         [-0.9882,  0.9869,  0.6460,  ..., -1.0000, -0.7331,  0.9544],\n",
       "         [-0.9747,  0.9971, -0.9989,  ..., -0.9997, -0.1188, -0.5962],\n",
       "         ...,\n",
       "         [-0.9987,  0.1622,  0.9288,  ..., -0.9847, -0.2392,  0.9679],\n",
       "         [-0.9993,  0.9703,  0.5753,  ..., -0.9924,  0.6781,  0.1950],\n",
       "         [-0.9420, -0.1723,  0.4745,  ..., -0.9792,  0.9248, -0.3226]]),\n",
       " torch.Size([32, 100]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating second layer of NN \n",
    "h = torch.tanh(emb.view(emb.shape[0], 6) @ W1 + b1)\n",
    "h, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6456cee-0f13-4af4-ab7f-8cf509bd48e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
